# PreguntaWiki: Asistente sobre Historia basado en Wikipedia.
**PreguntaWiki** es una aplicaci√≥n interactiva construida con **Streamlit** que permite hacer preguntas en espa√±ol sobre historia contempor√°nea en Europa (en principio este es el dominio elegido, pero se puede modificar al gusto de cada usuario). Utiliza art√≠culos de Wikipedia, una base de datos vectorial con **ChromaDB** y modelos LLM (como **LLaMA 3**) para generar respuestas contextualizadas.

---

## Funcionalidades

- B√∫squeda de art√≠culos por categor√≠a directamente desde Wikipedia.
- Descarga, vectorizaci√≥n y almacenamiento local de art√≠culos.
- Consulta sem√°ntica de contenidos usando embeddings.
- Asistente conversacional que responde preguntas basadas √∫nicamente en los documentos almacenados.
- Visualizaci√≥n, gesti√≥n y limpieza del contenido descargado.
- Opci√≥n para buscar directamente en Wikipedia si no hay suficiente contexto.

---

## Explicaci√≥n del c√≥digo

El c√≥digo est√° dividido en varios archivos que colaboran entre s√≠ para permitir la interacci√≥n con Wikipedia, la creaci√≥n de una base de datos sem√°ntica y la respuesta a preguntas usando un modelo LLM.

### `app.py` ‚Äì Interfaz de usuario (Streamlit)

Este es el archivo principal que se ejecuta para lanzar la aplicaci√≥n. Se encarga de:

- Mostrar el t√≠tulo y men√∫ lateral.
- Permitir b√∫squedas de art√≠culos por categor√≠a de Wikipedia.
- Descargar y almacenar art√≠culos en una base vectorial.
- Mostrar art√≠culos ya almacenados.
- Realizar preguntas basadas en los art√≠culos procesados.
- Visualizar las respuestas generadas y el historial conversacional.
- Ofrecer b√∫squedas adicionales en Wikipedia si no hay contexto suficiente.

> Este archivo gestiona toda la interacci√≥n del usuario y llama a las funciones del backend.

---
### `main.py` ‚Äì L√≥gica central de procesamiento
Contiene funciones clave para:

- Descargar art√≠culos y trocearlos para vectorizaci√≥n.
- Generar embeddings usando un modelo de HuggingFace.
- Crear prompts y enviar preguntas al modelo LLaMA 3.
- Recuperar documentos similares por b√∫squeda sem√°ntica.
- Buscar directamente en Wikipedia si no se encuentra informaci√≥n suficiente en la base local.

> Este archivo orquesta todo el flujo RAG (retrieval-augmented generation).

---
### `config.py`

Archivo con variables de configuraci√≥n reutilizables en todo el proyecto:

- `INDEX_NAME`: nombre de la colecci√≥n en ChromaDB.
- `FILE_LIST`: archivo local donde se guardan los t√≠tulos de art√≠culos descargados.
- `CHROMA_HOST` y `CHROMA_PORT`: configuraci√≥n de red del servidor Chroma.
- `EMBEDDING_MODEL`: modelo de embeddings usado para vectorizaci√≥n.
- `LLM_MODEL`: nombre del modelo LLama que se utilizar√° v√≠a `ollama`.
- `LLM_BASE_URL`
- `CHROMA_CLIENT`: inicializa el cliente de Chroma.
- `CATEGORIA_INICIAL`: la categor√≠a con la que se quiere trabajar en la aplicaci√≥n.
- 

> Centraliza todos los valores de configuraci√≥n para facilitar mantenimiento y cambios.
---

### `utils/` (carpeta de utilidades)

#### `wikipedia_utils.py`

Contiene funciones para interactuar con la Wikipedia:

- `get_wikipedia_articles`: obtiene t√≠tulos de una categor√≠a.
- `get_article_summary`: extrae el resumen de un art√≠culo.
- `is_article_in_chroma`: comprueba si el art√≠culo est√° guardado en la base de datos vectorial.
- `store_wikipedia_articles`: guarda art√≠culos seleccionados como documentos, los trocea, vectoriza y almacena en ChromaDB.

#### `db_utils.py`

Utilidades para gestionar la base de datos local:

- `save_name_files` y `load_name_files`: guardan y leen los nombres de los art√≠culos procesados.
- `clean_files`: borra los registros y reinicia la colecci√≥n en ChromaDB.
- `buscar_en_wikipedia`: busca un t√©rmino directamente en Wikipedia.
- `delete_specific_articles`: elimina art√≠culos espec√≠ficos de los que est√°n ya guardados.

#### `reset_utils.py`

Funci√≥n que se encarga de resetear la aplicaci√≥n cada vez que se cierra para que si un usuario hace alg√∫n cambio, que la siguiente
persona que utilice el sistema no se encuentre con los cambios del anterior usuario.

---

### `requirements.txt`

Lista de dependencias necesarias para ejecutar el proyecto. Incluye:

- `streamlit`: para la interfaz web.
- `chromadb`: para la base vectorial.
- `langchain`: para la orquestaci√≥n del flujo de recuperaci√≥n + generaci√≥n.
- `sentence-transformers`: para embeddings.
- `pypdf`: por si se ampl√≠a a fuentes en PDF (aunque actualmente no se usa directamente).

---

### `articulos.txt`

Archivo que guarda los nombres de los art√≠culos de Wikipedia que ya han sido procesados, evitando duplicados al almacenar nueva informaci√≥n.

## üöÄ C√≥mo desplegar el proyecto

Para ejecutar la aplicaci√≥n de forma local, solo necesitas seguir estos dos pasos principales: lanzar el servidor de ChromaDB usando Docker y ejecutar la interfaz con Streamlit desde la terminal.

---

### 1. Lanzar ChromaDB usando Docker

Aseg√∫rate de tener Docker instalado en tu sistema. Luego, ejecuta el siguiente comando en una terminal para iniciar el servidor de ChromaDB:

docker run -p 8000:8000 ghcr.io/chroma-core/chroma

### 2. Ejecutar la aplicaci√≥n con Streamlit

Para lanzar la interfaz web de la aplicaci√≥n, sigue estos pasos:

1. Abre una terminal (CMD o PowerShell).
2. Accede a la carpeta donde tienes tu proyecto. Por ejemplo:

cd C:\Users\TuUsuario\Ruta\Del\Proyecto\tfg_app

3. Ejecuta el siguiente comando para iniciar Streamlit:

python -m streamlit run app.py

Esto abrir√° autom√°ticamente la aplicaci√≥n en tu navegador.
Desde all√≠ podr√°s interactuar con la interfaz: buscar art√≠culos, hacer preguntas y visualizar respuestas generadas por el modelo.


